import numpy as np
import matplotlib.pyplot as plt

# loading file to array data
data = np.loadtxt('items.txt', delimiter=",")
# print the shape the array data
# print(data.shape)

# plot the data
X = data[:, 0]  #  get the first column of all rows 
y = data[:, 1]  #  get the second column of all rows

plt.scatter(X, y)
plt.xticks(np.arange(5,30,step=6))
plt.yticks(np.arange(-5,30,step=6))
plt.xlabel("Weight of Grocery Store Items (grams)")
plt.ylabel("Fragility (Ranking #)")
plt.title("Fragility of Various Grocery Store Items")

X = X.reshape(X.shape[0], 1) # same as X[:, np.newaxis]
print(X.shape)

y = y.reshape(-1, 1) # same as y.reshape(y.shape[0], 1)
print(y.shape)

from sklearn.linear_model import LinearRegression

# load the model and fit in our data
model = LinearRegression(fit_intercept=True)
model.fit(X, y)

y_hat = model.predict(X)
# plot our training data points, and the fit line
plt.scatter(X, y)
plt.plot(X, y_hat)

import matplotlib.pyplot as plt
import numpy as np
import os
import PIL
import tensorflow as tf

from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential

from google.colab import drive

drive.mount('/content/gdrive')

!ls /content/gdrive/MyDrive

batch_size = 32   # you can change this, maybe you want to try a few different batch sizes
img_height = 400  # don't change this
img_width = 400   # don't change this

train_ds = tf.keras.utils.image_dataset_from_directory(
  "/content/gdrive/MyDrive/images_FINAL",    # the path of ASL_data on your googld drive something like /content/gdrive/My Drive/CS497_Assignment5_data/ASL_data
  validation_split=0.2, #apparently cannot make this less than 0.167 or i will get an error
  subset="training",
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size)
